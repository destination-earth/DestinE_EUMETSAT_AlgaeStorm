{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6ffda6b-b589-4140-900e-f40fa44067f9",
   "metadata": {},
   "source": [
    "## CNN model for time-series forcasting Oa08 reflectance band for sea surface colour dataset from Sentinel 3a \n",
    "### Author: Smita Chakraborty, RISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c0a167-25ae-4b35-92b9-54190c863227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 12:58:28.594512: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 12:58:28.613364: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 12:58:28.619001: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-23 12:58:28.633641: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 12:58:29.598794: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eumartools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m boto3_connect\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m product\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrio\u001b[39;00m\n",
      "File \u001b[0;32m~/DestinE-DataLake-Lab/sc_algaebloom/utils.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01meumartools\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eumartools'"
     ]
    }
   ],
   "source": [
    "##libraries for ML tasks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, LSTM, TimeDistributed, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import tifffile as tiff\n",
    "from tensordict import TensorDict\n",
    "import pandas as pd\n",
    "\n",
    "## libraries for s3 bucket connection: read input and write output\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from utils import boto3_connect\n",
    "from itertools import product\n",
    "import rasterio as rio\n",
    "from rasterio import windows\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bfe084-1d04-48cd-8bcb-5bcbd4b7cf4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read tiff files\n",
    "def read_tiff(img, outx):\n",
    "\n",
    "    # Convert to grayscale if it's not already\n",
    "    #if img.mode != 'L':\n",
    "    #   img = img.convert('L')\n",
    "\n",
    "    # Convert to numpy array\n",
    "    #img_array = np.array(img)\n",
    "    \n",
    "    #rasterio to read pixel values, 1000 x 1000 array\n",
    "    pix_val = img.read(1) \n",
    "    \n",
    "    #returns date\n",
    "    #so im.tags()[\"date\"]\n",
    "    \n",
    "    #skip nan tiffs\n",
    "    if np.all(np.isnan(pix_val)) is False:\n",
    "\n",
    "        # Normalize to [0, 1] range\n",
    "        norm = (pix_val - np.nanmin(pix_val))/(np.nanmax(pix_val) - np.nanmin(pix_val))\n",
    "        #img_array = img_array.astype(np.float32) / 255 #change to x-min/max-min\n",
    "\n",
    "        # adds a channel dimension to the array(shape becomes [1, height, width, norm_pix_val]).\n",
    "        #need to add norm\n",
    "        #img_array = np.expand_dims(pix_val, axis=0)\n",
    "\n",
    "        # Convert to PyTorch tensor\n",
    "        #tensor = torch.from_numpy(pix_val) #img_array\n",
    "\n",
    "        # Adds a batch dimension to the tensor, making its shape [1, 1, height, width]\n",
    "        #tensor = tensor.unsqueeze(0)\n",
    "\n",
    "        outx.append(norm)\n",
    "    \n",
    "    return outx\n",
    "        #print(outx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39268e3a-8650-423a-848f-856b38a23dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## login credentials to DEDL platform from the .env file in parent directory\n",
    "load_dotenv()\n",
    "USERNAME=os.getenv('DEDL_USERNAME')\n",
    "PASSWORD=os.getenv('DEDL_PASSWORD')\n",
    "ACCESS_KEY=os.getenv('S3_ACCESS_KEY')\n",
    "SECRET_KEY=os.getenv('S3_SECRET_KEY')\n",
    "\n",
    "s3=boto3_connect(ACCESS_KEY, SECRET_KEY)\n",
    "\n",
    "s3buc = s3.Bucket('algaestorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483f4b2-e310-43ce-911b-ec9508fe2c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for obj in s3buc.objects.filter(Prefix=\"eodata/split_img/\"):\n",
    "#    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ea7fc-bc6d-4136-9eca-0051c7a817b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a list of tensors for the input conv2d layer\n",
    "outx = []\n",
    "\n",
    "for obj in s3buc.objects.filter(Prefix=\"eodata/split_img/S3A_OL_2_WFR____20190602T084749_20190602T085049_20190603T201514_0179_045_221_1980_MAR_O_NT_002.SEN3/\"): #S3A_OL_2_WFR____20190603T082138_20190603T082438_20190604T171448_0179_045_235_1980_MAR_O_NT_002.SEN3/\n",
    "    #loops through all tiffs in 1 day\n",
    "    ##connecting to s3 bucket repository \n",
    "    #s3obj=s3.Object(bucket_name='algaestorm',key='https://cloud.central.data.destination-earth.eu/project/containers/container/algaestorm/eodata/Sentinel-3/OLCI/OL_2_WFR/2019/04/')\n",
    "    body = obj.get()['Body'].read()\n",
    "    filelike=BytesIO(body)\n",
    "    with rio.open(filelike, mode='r') as im:\n",
    "\n",
    "        date=im.tags()[\"date\"] \n",
    "        \n",
    "        #check dimension of the file\n",
    "        x_dim = im.width\n",
    "        y_dim = im.height\n",
    "        \n",
    "        val = im.read(1)\n",
    "        \n",
    "        chk = ~np.all(np.isnan(val))\n",
    "        #print(np.all(np.isnan(val)), chk)\n",
    "        \n",
    "        if (x_dim, y_dim) == (1000, 1000) and chk:\n",
    "            \n",
    "            # Normalize to [0, 1] range\n",
    "            norm = (val - np.nanmin(val))/(np.nanmax(val) - np.nanmin(val))\n",
    "            \n",
    "            #read tiff files and builds a list of tensors\n",
    "            #outx = read_tiff(im, outx)\n",
    "            \n",
    "            #print(norm, x_dim, y_dim)\n",
    "            \n",
    "            #Convert to PyTorch tensor \n",
    "            tensor = torch.from_numpy(norm) \n",
    "            \n",
    "            # Adds a batch dimension to the tensor, making its shape [1, 1, height, width]\n",
    "            #tensor = tensor.unsqueeze(0)\n",
    "            \n",
    "            # Adds a channel dimension to the tensor, making its shape [1, height, width, 1]\n",
    "            tensor = tensor.unsqueeze(2)\n",
    "            \n",
    "            outx.append(tensor)\n",
    "                                                                                                                                                                            \n",
    "\n",
    "#print(outx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6be82-1075-4f82-a1b7-13853c443c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a tensor of the list of tensors\n",
    "result = torch.stack(outx, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c9afa2-2a39-4654-860a-9969d2f2ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape of the output tensor, should have the shape:\n",
    "# (batch size, img_height, img_width, channels) as conv2d accepts 4D tensor\n",
    "tf.shape(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d32fbc-618b-42ae-9bd3-c2918eaeb506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a list of tensors for the input conv2d layer for a second date\n",
    "outx_2 = []\n",
    "\n",
    "##connecting to s3 bucket repository \n",
    "for obj in s3buc.objects.filter(Prefix=\"eodata/split_img/S3A_OL_2_WFR____20190603T082138_20190603T082438_20190604T171448_0179_045_235_1980_MAR_O_NT_002.SEN3/\"): #S3A_OL_2_WFR____20190603T082138_20190603T082438_20190604T171448_0179_045_235_1980_MAR_O_NT_002.SEN3/\n",
    "    #loops through all tiffs in 1 day\n",
    "    #s3obj=s3.Object(bucket_name='algaestorm',key='https://cloud.central.data.destination-earth.eu/project/containers/container/algaestorm/eodata/Sentinel-3/OLCI/OL_2_WFR/2019/04/')\n",
    "    body = obj.get()['Body'].read()\n",
    "    filelike=BytesIO(body)\n",
    "    with rio.open(filelike, mode='r') as im:\n",
    "\n",
    "        #date=im.tags()[\"date\"] \n",
    "        \n",
    "        #check dimension of the file\n",
    "        x_dim = im.width\n",
    "        y_dim = im.height\n",
    "        \n",
    "        val = im.read(1)\n",
    "        \n",
    "        chk = ~np.all(np.isnan(val))\n",
    "        #print(np.all(np.isnan(val)), chk)\n",
    "        \n",
    "        if (x_dim, y_dim) == (1000, 1000) and chk:\n",
    "            \n",
    "            # Normalize to [0, 1] range\n",
    "            norm = (val - np.nanmin(val))/(np.nanmax(val) - np.nanmin(val))\n",
    "            \n",
    "            #read tiff files and builds a list of tensors\n",
    "            #outx = read_tiff(im, outx)\n",
    "            \n",
    "            #print(norm, x_dim, y_dim)\n",
    "            \n",
    "            #Convert to PyTorch tensor\n",
    "            tensor = torch.from_numpy(norm) \n",
    "            \n",
    "            # Adds a batch dimension to the tensor, making its shape [1, 1, height, width]\n",
    "            #tensor = tensor.unsqueeze(0)\n",
    "            \n",
    "            # Adds a channel dimension to the tensor, making its shape [1, height, width, channel]\n",
    "            tensor = tensor.unsqueeze(2)\n",
    "            \n",
    "            outx_2.append(tensor)\n",
    "                                                                                                                                                                            \n",
    "\n",
    "#print(outx_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7257d92-7c89-4faa-97b9-80d3a61aa139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a tensor of the list of tensors\n",
    "result2 = torch.stack(outx_2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e497815-201a-4c65-bee2-8f2ac2e0481f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check the shape of the output tensor, should have the shape:\n",
    "# (batch size, img_height, img_width, channels) as conv2d accepts 4D tensor\n",
    "tf.shape(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605904a2-5c1d-4746-a1fb-efa85b8c02ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This aproach is discouraged as it is inefficient due to the size of the flattened tensor\n",
    "\n",
    "    #Define the model with a Dense layer\n",
    "    #rescaling and conv2D as this exceeds memory\n",
    "#model = tf.keras.Sequential([\n",
    " #   layers.Flatten(input_shape=result.shape),\n",
    " #   layers.Dense(units=1000000, activation='linear')\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02bd628-be43-45c6-98b3-1a049110aa0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace nan values with zero for now, \n",
    "# nan hinders the model from learning even if some pixel values are non-zero\n",
    "def replace_nan_with_zero(tensor):\n",
    "    return tf.where(tf.math.is_nan(tensor), tf.zeros_like(tensor), tensor)\n",
    "\n",
    "result = replace_nan_with_zero(result)\n",
    "result2 = replace_nan_with_zero(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1e958-b966-4df6-a59d-af4851d32066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the tensor to reduce batch size\n",
    "reduced_result = result[:6, :, :, :]\n",
    "\n",
    "# Split the tensor into two parts along the batch dimension if want to use both/all parts of a tensor from \n",
    "# a single day\n",
    "#part1, part2 = tf.split(result, num_or_size_splits=2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39b242-5644-4224-afe0-53a0c7ab7a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#the main conv2D layers\n",
    "img_height= 1000\n",
    "img_width= 1000\n",
    "model = tf.keras.Sequential([\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same'), #16 filters, 3 x 3 kernel size\n",
    "        layers.Conv2D(1, (1, 1), activation='relu', padding='same'), #1 filter, 1 x 1 kernel size\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf170af-dda2-4492-a92e-93170a8d2ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Predict pixel values\n",
    "predicted_values = model.predict(reduced_result)\n",
    "\n",
    "#print(predicted_values)\n",
    "\n",
    "#prints shape of predicted tensor\n",
    "print(predicted_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3d8b4-42f6-4265-b875-dcf70bcf9abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a new list of tensors from a third date\n",
    "pred = []\n",
    "\n",
    "for obj in s3buc.objects.filter(Prefix=\"eodata/split_img/S3A_OL_2_WFR____20190605T091015_20190605T091315_20190606T200225_0179_045_264_1980_MAR_O_NT_002.SEN3/\"): #S3A_OL_2_WFR____20190603T082138_20190603T082438_20190604T171448_0179_045_235_1980_MAR_O_NT_002.SEN3/\n",
    "    #loops through all tiffs in 1 day\n",
    "    body = obj.get()['Body'].read()\n",
    "    filelike=BytesIO(body)\n",
    "    with rio.open(filelike, mode='r') as im:\n",
    "\n",
    "        date=im.tags()[\"date\"] \n",
    "        \n",
    "        #check dimension of the file\n",
    "        x_dim = im.width\n",
    "        y_dim = im.height\n",
    "        \n",
    "        val = im.read(1)\n",
    "        \n",
    "        chk = ~np.all(np.isnan(val))\n",
    "        #print(np.all(np.isnan(val)), chk)\n",
    "        print(np.nanmin(val))\n",
    "        \n",
    "        if (x_dim, y_dim) == (1000, 1000) and chk:\n",
    "            \n",
    "            # Normalize to [0, 1] range\n",
    "            p_norm = (val - np.nanmin(val))/(np.nanmax(val) - np.nanmin(val))\n",
    "            \n",
    "            #read tiff files and builds a list of tensors\n",
    "            #outx = read_tiff(im, outx)\n",
    "            \n",
    "            #print(norm, x_dim, y_dim)\n",
    "            p_tensor = torch.from_numpy(p_norm) \n",
    "            \n",
    "            # Adds a batch dimension to the tensor, making its shape [1, 1, height, width]\n",
    "            #tensor = tensor.unsqueeze(0)\n",
    "            \n",
    "            # Adds a channel dimension to the tensor, making its shape [1, height, width, 1]\n",
    "            p_tensor = p_tensor.unsqueeze(2)\n",
    "            \n",
    "            pred.append(p_tensor)\n",
    "                                                                                                                                                                            \n",
    "\n",
    "#print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e9f12-ad96-4ca8-840c-cf0e54f96e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a tensor of the list of tensors\n",
    "pred_result = torch.stack(pred, 0)\n",
    "\n",
    "# Slice the tensor to reduce batch size\n",
    "reduced_predresult = pred_result[:6, :, :, :]\n",
    "\n",
    "# Split the tensor into two parts along the batch dimension\n",
    "#part1, part2 = tf.split(pred_result, num_or_size_splits=2, axis=0)\n",
    "\n",
    "print(pred_result.shape) #original shape of the target tensor\n",
    "print(reduced_predresult.shape) #modified shape of the target tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9cbc16-e952-4de0-b61b-ac591539de05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_nan_with_zero(tensor):\n",
    "    return tf.where(tf.math.is_nan(tensor), tf.zeros_like(tensor), tensor)\n",
    "\n",
    "reduced_predresult = replace_nan_with_zero(reduced_predresult)\n",
    "\n",
    "def count_nans(tensor):\n",
    "    nan_mask = tf.math.is_nan(tensor)\n",
    "    nan_count = tf.reduce_sum(tf.cast(nan_mask, tf.int32))\n",
    "    return nan_count\n",
    "\n",
    "nan_count_1 = count_nans(predicted_values)\n",
    "nan_count_2 = count_nans(reduced_predresult)\n",
    "\n",
    "print(\"Number of nan in pred:\", nan_count_1) #returns number of nan in the predicted tensor, should be zero\n",
    "print(\"Number of nan in target:\", nan_count_2) #returns number of nan in the nan-removed target tensor, should be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7a9a2-1ccc-4a30-aa0a-4d31a24a9657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculates root mean squared error based on predicted tensor and unseen tensor\n",
    "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "rmse.update_state(predicted_values, reduced_predresult)\n",
    "rmse.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069248f-80b1-409d-8633-b49fbc50ffb9",
   "metadata": {},
   "source": [
    "### Training loop and plotting the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec6cc4-7fc4-4b9c-9982-8fee01c9cc24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#'model' is our CNN model and 'result' and 'result2' are our tensors\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 30\n",
    "\n",
    "# Initialize a list to store loss values\n",
    "loss_history = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Train on 'result' tensor\n",
    "    history = model.fit(reduced_result, reduced_result, epochs=epochs, verbose=0)\n",
    "    loss_history.append(history.history['loss'][0])\n",
    "    \n",
    "    # Train on 'result2' tensor\n",
    "    #history = model.fit(result2, result2, epochs=epochs, verbose=0)\n",
    "    #loss_history.append(history.history['loss'][0])\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss_history[-1]:.8f}\")\n",
    "\n",
    "# Predict pixel values using the trained model\n",
    "predicted_values_lp = model.predict(reduced_result)\n",
    "\n",
    "# Print final loss\n",
    "print(f\"Final loss: {loss_history[-1]:.8f}\")\n",
    "\n",
    "# You can plot the loss history if desired\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history)\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "# Save the image using matplotlib.pyplot.imsave()\n",
    "plt.savefig('modelOa08_loss_result1_1_30.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b68297-8e7c-4ad9-9630-f92c791dee5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculates root mean squared error based on predicted tensor and unseen tensor\n",
    "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "rmse.update_state(predicted_values_lp, reduced_predresult) #reduced_predresult is our target\n",
    "rmse.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f4b586-67b9-4f01-af4f-30520999765b",
   "metadata": {},
   "source": [
    "Predicted_values_lp is the prediction\n",
    "\n",
    "reduced_predresult is the target\n",
    "\n",
    "reduced_result, result_2 are training tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae45cb1-6a07-4252-8022-5af08917cd45",
   "metadata": {},
   "source": [
    "## Plotting the results and the new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb5047-bb05-486e-ba24-cf8e84cc16fb",
   "metadata": {},
   "source": [
    "### Plotting a SNS heatmap visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f6fd25-f3c9-44cf-88a8-bd5181e6d715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plots a seaborn heatmap of the input tensor\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 15))\n",
    "fig.suptitle('Heatmaps of Tensor Slices', fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    sns.heatmap(reduced_result[i, :, :, 0], cmap='viridis', ax=ax, cbar=True)\n",
    "    ax.set_title(f'Slice {i+1}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to accommodate subtitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf916ecd-4d17-400d-ad47-ca099a61bbe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plots a seaborn heatmap of the predicted tensor\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 15))\n",
    "fig.suptitle('Heatmaps of Tensor Slices', fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    sns.heatmap(predicted_values_lp[i, :, :, 0], cmap='viridis', ax=ax, cbar=True)\n",
    "    ax.set_title(f'Slice {i+1}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to accommodate suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a61bf-9a86-4d83-a34b-6822f3f813ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plots a seaborn heatmap of the output tensor scaled to 0.0012 x \\pi = 0.003768 as the threshold value\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 15))\n",
    "fig.suptitle('Heatmaps of Tensor Slices', fontsize=16)\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    # Calculate the maximum value in the tensor slice\n",
    "    vmax = np.max(predicted_values[i, :, :, 0])\n",
    "    # Set vmin to 0.003768 and use the calculated vmax\n",
    "    sns.heatmap(predicted_values_lp[i, :, :, 0], cmap='viridis', vmin=0.003768, vmax=vmax, ax=ax, cbar=True)\n",
    "    #sns.heatmap(predicted_values[i, :, :, 0], cmap='viridis', ax=ax, cbar=True)\n",
    "    ax.set_title(f'Slice {i+1}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to accommodate suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6697e3-18e8-4c7a-b032-178e936adf24",
   "metadata": {},
   "source": [
    "### Plots a 3D surface plot of the input \\& predicted tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82bfed6-9fed-4b20-b5cc-fd8c94b081a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(2, 3, i+1, projection='3d')\n",
    "    x, y = np.meshgrid(range(0, 1000, 10), range(0, 1000, 10))  # Downsampling for performance\n",
    "    ax.plot_surface(x, y, reduced_result[i, ::10, ::10, 0], cmap='viridis')\n",
    "    ax.set_title(f'3D Surface Plot of Slice {i+1}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#fig = plt.figure(figsize=(12, 10))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#x, y = np.meshgrid(range(1000), range(1000))\n",
    "#ax.plot_surface(x, y, result[0, :, :, 0], cmap='viridis')\n",
    "#plt.title('3D Surface Plot of First Slice')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddf937-7ccf-4b3e-aba9-141a46af78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(2, 3, i+1, projection='3d')\n",
    "    x, y = np.meshgrid(range(0, 1000, 10), range(0, 1000, 10))  # Downsampling for performance\n",
    "    \n",
    "    # Apply the lower cut value\n",
    "    z = predicted_values_lp[i, ::10, ::10, 0]\n",
    "    z = np.maximum(z, 0.00376)\n",
    "    \n",
    "    # Plot the surface\n",
    "    surf = ax.plot_surface(x, y, z, cmap='viridis')\n",
    "    \n",
    "    ax.set_title(f'3D Surface Plot of Slice {i+1}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Value')\n",
    "    \n",
    "    # Set the minimum z-axis value to 0.00376\n",
    "    ax.set_zlim(bottom=0.00376)\n",
    "    \n",
    "    # Add a color bar\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2dc231-952a-485f-80d8-53f31bbb188b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "##Thresholds\n",
    "##surface_TH = 0.0012 * np.pi (band for 665 nm)  ---> Oa08\n",
    "##subsurface_TH = 0.00435 * np.pi * .9 (band for 560 nm) ---> Oa06\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(2, 3, i+1, projection='3d')\n",
    "    x, y = np.meshgrid(range(0, 1000, 10), range(0, 1000, 10))  # Downsampling for performance\n",
    "    ax.plot_surface(x, y, predicted_values_lp[i, ::10, ::10, 0], cmap='viridis')\n",
    "    ax.set_title(f'3D Surface Plot of Slice {i+1}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50d751-a48e-4e79-82da-a99e87e6b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "##Thresholds\n",
    "##surface_TH = 0.0012 * np.pi (band for 665 nm)  ---> Oa08\n",
    "##subsurface_TH = 0.00435 * np.pi * .9 (band for 560 nm) ---> Oa06\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(2, 3, i+1, projection='3d')\n",
    "    x, y = np.meshgrid(range(0, 1000, 10), range(0, 1000, 10))  # Downsampling for performance\n",
    "    ax.plot_surface(x, y, reduced_predresult[i, ::10, ::10, 0], cmap='viridis')\n",
    "    ax.set_title(f'3D Surface Plot of Slice {i+1}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702985f-71cd-4202-8240-958a237a03c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aug_env",
   "language": "python",
   "name": "aug_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
